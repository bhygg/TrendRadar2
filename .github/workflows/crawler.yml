name: ğŸ­ ä¸“ä¸šäº§ä¸šå†…å‚ç›‘æµ‹ç³»ç»Ÿ
on:
  # å®æ—¶æ•°æ®é‡‡é›†ï¼šæ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡ï¼ˆUTCæ—¶é—´ï¼‰
  schedule:
    - cron: "0 * * * *"  # æ¯å°æ—¶æ•´ç‚¹
  
  # æ—¥æŠ¥ç”Ÿæˆï¼šåŒ—äº¬æ—¶é—´8ç‚¹ï¼ˆå¯¹åº”UTCæ—¶é—´0ç‚¹ï¼‰
    - cron: "0 0 * * *"  # æ¯å¤©UTCæ—¶é—´0ç‚¹
  
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      operation:
        description: 'é€‰æ‹©æ“ä½œç±»å‹'
        required: true
        default: 'collect'
        type: choice
        options:
          - collect
          - report
          - test
          - full

concurrency:
  group: industrial-intelligence-${{ github.ref }}
  cancel-in-progress: false

permissions:
  contents: write

env:
  PYTHON_VERSION: '3.10'
  TZ: 'Asia/Shanghai'

jobs:
  # ä»»åŠ¡1ï¼šæ•°æ®é‡‡é›†ä¸å¤„ç†
  crawl-and-process:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      has_data: ${{ steps.check_data.outputs.has_data }}
      data_file: ${{ steps.check_data.outputs.data_file }}
    
    steps:
      - name: ğŸ›ï¸ æ£€å‡ºä»£ç 
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          clean: true
          
      - name: âš™ï¸ è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: ğŸ“¦ å®‰è£…ä¾èµ–
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: ğŸ”§ ç”Ÿæˆæ—¶é—´æˆ³
        id: timestamp
        run: |
          echo "timestamp=$(TZ='Asia/Shanghai' date +'%Y%m%d_%H%M%S')" >> $GITHUB_OUTPUT
          echo "date=$(TZ='Asia/Shanghai' date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
          echo "date_dir=$(TZ='Asia/Shanghai' date +'%Yå¹´%mæœˆ%dæ—¥')" >> $GITHUB_OUTPUT
          
      - name: ğŸ” é…ç½®æ£€æŸ¥
        run: |
          echo "ğŸ” æ£€æŸ¥é…ç½®æ–‡ä»¶..."
          ls -la config/
          echo "ğŸ“Š ç³»ç»Ÿé…ç½®ï¼š"
          echo "- æ—¶åŒº: ${{ env.TZ }}"
          echo "- è¿è¡Œæ—¶é—´: ${{ steps.timestamp.outputs.timestamp }}"
          
      - name: ğŸ“¡ è¿è¡Œæ•°æ®é‡‡é›†
        id: crawl
        env:
          GITHUB_ACTIONS: true
          ENABLE_NOTIFICATION: "false"
          REPORT_MODE: "incremental"
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        run: |
          echo "ğŸ• å¼€å§‹é‡‡é›†æ•°æ®..."
          
          # æ£€æŸ¥main.pyæ”¯æŒçš„å‚æ•°
          echo "ğŸ“‹ æ£€æŸ¥main.pyå‚æ•°..."
          python main.py --help || true
          
          # è¿è¡Œä¸»ç¨‹åºï¼ˆæ ¹æ®ä½ çš„main.pyå®é™…å‚æ•°ï¼‰
          echo "ğŸš€ è¿è¡Œä¸»ç¨‹åº..."
          
          # æ–¹æ¡ˆ1ï¼šå¦‚æœmain.pyæ”¯æŒ--modeå‚æ•°
          python main.py --mode=incremental --no-notification || python main.py
          
          # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
          echo "ğŸ“ æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶..."
          find . -name "*.json" -type f | head -10
          find . -name "*.txt" -type f | head -10
          find . -name "*.html" -type f | head -10
          
      - name: ğŸ“Š å¤„ç†è¾“å‡ºæ–‡ä»¶
        id: process_output
        run: |
          echo "ğŸ”„ å¤„ç†è¾“å‡ºæ–‡ä»¶..."
          
          # æ£€æŸ¥main.pyç”Ÿæˆçš„ç›®å½•ç»“æ„
          ls -la output/ || echo "outputç›®å½•ä¸å­˜åœ¨"
          
          # å¦‚æœæœ‰outputç›®å½•ï¼ŒæŸ¥æ‰¾æœ€æ–°ç”Ÿæˆçš„æ–‡ä»¶
          if [ -d "output" ]; then
            echo "ğŸ“ æ‰¾åˆ°outputç›®å½•ï¼ŒæŸ¥æ‰¾æ•°æ®æ–‡ä»¶..."
            
            # æŸ¥æ‰¾æœ€æ–°çš„txtæ–‡ä»¶ï¼ˆåŒ…å«åŸå§‹æ•°æ®ï¼‰
            latest_txt=$(find output -name "*.txt" -type f -exec ls -t {} + | head -1)
            
            if [ -n "$latest_txt" ]; then
              echo "âœ… æ‰¾åˆ°æœ€æ–°æ•°æ®æ–‡ä»¶: $latest_txt"
              
              # åˆ›å»ºdataç›®å½•å¹¶å¤åˆ¶æ–‡ä»¶
              mkdir -p data/hourly
              mkdir -p data/raw
              
              # å¤åˆ¶txtæ–‡ä»¶
              cp "$latest_txt" "data/raw/news_${{ steps.timestamp.outputs.timestamp }}.txt"
              
              # å°†txtè½¬æ¢ä¸ºjsonæ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
              echo "ğŸ”„ è½¬æ¢æ•°æ®æ ¼å¼..."
              python -c "
import json
import sys

# è¯»å–txtæ–‡ä»¶
file_path = 'data/raw/news_${{ steps.timestamp.outputs.timestamp }}.txt'
output_path = 'data/hourly/news_${{ steps.timestamp.outputs.timestamp }}.json'

try:
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # è§£ætxtæ ¼å¼
    news_items = []
    current_item = {}
    
    for line in lines:
        line = line.strip()
        if line.startswith('ã€'):
            # å¯èƒ½æ˜¯æ–°é—»æ ‡é¢˜
            if current_item:
                news_items.append(current_item)
            current_item = {'title': line, 'source': 'unknown'}
        elif line and current_item:
            # å¯èƒ½æ˜¯å…¶ä»–ä¿¡æ¯
            if 'detail' not in current_item:
                current_item['detail'] = line
            else:
                current_item['detail'] += ' ' + line
    
    if current_item:
        news_items.append(current_item)
    
    # ä¿å­˜ä¸ºjson
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': '${{ steps.timestamp.outputs.timestamp }}',
            'date': '${{ steps.timestamp.outputs.date }}',
            'count': len(news_items),
            'news': news_items
        }, f, ensure_ascii=False, indent=2)
    
    print(f'âœ… è½¬æ¢å®Œæˆ: {len(news_items)} æ¡æ–°é—»')
    
except Exception as e:
    print(f'âŒ è½¬æ¢å¤±è´¥: {str(e)}')
    # åˆ›å»ºä¸€ä¸ªç©ºjsonæ–‡ä»¶
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': '${{ steps.timestamp.outputs.timestamp }}',
            'date': '${{ steps.timestamp.outputs.date }}',
            'count': 0,
            'news': []
        }, f, ensure_ascii=False, indent=2)
              "
              
              # ç¡®ä¿jsonæ–‡ä»¶å­˜åœ¨
              if [ -f "data/hourly/news_${{ steps.timestamp.outputs.timestamp }}.json" ]; then
                echo "data_file=data/hourly/news_${{ steps.timestamp.outputs.timestamp }}.json" >> $GITHUB_OUTPUT
                echo "âœ… JSONæ•°æ®æ–‡ä»¶å·²åˆ›å»º"
              else
                echo "data_file=data/hourly/empty_${{ steps.timestamp.outputs.timestamp }}.json" >> $GITHUB_OUTPUT
                echo "âš ï¸ ä½¿ç”¨ç©ºJSONæ–‡ä»¶"
              fi
            else
              echo "data_file=data/hourly/empty_${{ steps.timestamp.outputs.timestamp }}.json" >> $GITHUB_OUTPUT
              echo "âš ï¸ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œåˆ›å»ºç©ºæ–‡ä»¶"
            fi
          else
            echo "data_file=data/hourly/empty_${{ steps.timestamp.outputs.timestamp }}.json" >> $GITHUB_OUTPUT
            echo "âš ï¸ outputç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºç©ºæ–‡ä»¶"
          fi
          
          # åˆ›å»ºdataç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
          mkdir -p data/hourly
          
      - name: ğŸ“‹ æ£€æŸ¥æ•°æ®æ–‡ä»¶
        id: check_data
        run: |
          echo "ğŸ” æ£€æŸ¥æ•°æ®æ–‡ä»¶..."
          
          # ç¡®ä¿data_fileå˜é‡å­˜åœ¨
          data_file="${{ steps.process_output.outputs.data_file }}"
          
          if [ -z "$data_file" ]; then
            data_file="data/hourly/news_${{ steps.timestamp.outputs.timestamp }}.json"
          fi
          
          # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶
          if [ ! -f "$data_file" ]; then
            echo "âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºç©ºæ–‡ä»¶..."
            mkdir -p data/hourly
            echo '{"timestamp": "${{ steps.timestamp.outputs.timestamp }}", "date": "${{ steps.timestamp.outputs.date }}", "count": 0, "news": []}' > "$data_file"
          fi
          
          # æ£€æŸ¥æ–‡ä»¶å†…å®¹
          count=$(python -c "import json; f=open('$data_file'); data=json.load(f); print(data.get('count', 0)); f.close()")
          echo "ğŸ“Š æ•°æ®ç»Ÿè®¡: $count æ¡æ–°é—»"
          
          # è®¾ç½®è¾“å‡º
          if [ $count -gt 0 ]; then
            echo "has_data=true" >> $GITHUB_OUTPUT
          else
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi
          
          echo "data_file=$data_file" >> $GITHUB_OUTPUT
          
      - name: ğŸ’¾ æ•°æ®å½’æ¡£
        if: steps.check_data.outputs.has_data == 'true'
        run: |
          echo "ğŸ“ å½’æ¡£æ•°æ®..."
          mkdir -p data/archive/hourly
          cp "${{ steps.check_data.outputs.data_file }}" data/archive/hourly/
          
      - name: ğŸ“ æäº¤æ•°æ®æ›´æ–°
        if: always()
        run: |
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          
          # æ·»åŠ æ•°æ®æ–‡ä»¶
          git add data/hourly/ data/raw/
          
          if git diff --cached --quiet; then
            echo "ğŸ“­ æ— æ–°æ•°æ®éœ€è¦æäº¤"
          else
            echo "ğŸ“ æäº¤æ•°æ®æ›´æ–°..."
            git commit -m "ğŸ“Š æ•°æ®æ›´æ–°: ${{ steps.timestamp.outputs.timestamp }}"
            
            # é‡è¯•æ¨é€
            for i in {1..3}; do
              echo "å°è¯•æ¨é€ ($i/3)..."
              if git pull --rebase origin main && git push origin main; then
                echo "âœ… æ¨é€æˆåŠŸ"
                break
              else
                echo "âš ï¸ æ¨é€å¤±è´¥ï¼Œç­‰å¾…10ç§’åé‡è¯•..."
                sleep 10
              fi
            done
          fi
          
  # ä»»åŠ¡2ï¼šæ—¥æŠ¥ç”Ÿæˆï¼ˆä¾èµ–æ•°æ®é‡‡é›†ï¼‰
  daily-report:
    needs: crawl-and-process
    if: github.event_name == 'schedule' || (github.event.inputs.operation == 'report' || github.event.inputs.operation == 'full')
    runs-on: ubuntu-latest
    timeout-minutes: 30
      
    steps:
      - name: ğŸ›ï¸ æ£€å‡ºä»£ç 
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          
      - name: âš™ï¸ è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: ğŸ“¦ å®‰è£…ä¾èµ–
        run: |
          pip install -r requirements.txt
          
      - name: ğŸ“… è®¾ç½®æ—¥æœŸ
        id: date
        run: |
          if [ -n "${{ github.event.inputs.date }}" ]; then
            target_date="${{ github.event.inputs.date }}"
          else
            target_date=$(TZ='Asia/Shanghai' date -d "yesterday" +'%Y-%m-%d')
          fi
          echo "target_date=$target_date" >> $GITHUB_OUTPUT
          echo "ğŸ“… æŠ¥å‘Šæ—¥æœŸ: $target_date"
          
      - name: ğŸ“Š å‡†å¤‡æ•°æ®
        run: |
          echo "ğŸ”„ å‡†å¤‡æ—¥æŠ¥æ•°æ®..."
          
          # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
          if [ "${{ needs.crawl-and-process.outputs.has_data }}" = "true" ]; then
            echo "âœ… æœ‰æ•°æ®å¯ç”¨ï¼Œä½¿ç”¨é‡‡é›†çš„æ•°æ®"
            data_file="${{ needs.crawl-and-process.outputs.data_file }}"
            cp "$data_file" data/daily_input.json
          else
            echo "âš ï¸ æ— æ–°æ•°æ®ï¼Œå°è¯•ä½¿ç”¨ç°æœ‰æ•°æ®"
            
            # æŸ¥æ‰¾æœ€è¿‘çš„æ•°æ®æ–‡ä»¶
            recent_file=$(find data/hourly -name "*.json" -type f -exec ls -t {} + | head -1)
            if [ -n "$recent_file" ]; then
              echo "ğŸ“ ä½¿ç”¨æœ€è¿‘çš„æ–‡ä»¶: $recent_file"
              cp "$recent_file" data/daily_input.json
            else
              echo "âŒ æ— æ•°æ®å¯ç”¨ï¼Œåˆ›å»ºç©ºæ–‡ä»¶"
              echo '{"timestamp": "${{ steps.date.outputs.target_date }}", "count": 0, "news": []}' > data/daily_input.json
            fi
          fi
          
      - name: ğŸ“‹ ç”Ÿæˆæ—¥æŠ¥
        id: generate_report
        env:
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          ENABLE_NOTIFICATION: "true"
          REPORT_MODE: "daily"
        run: |
          echo "ğŸ“‹ ç”Ÿæˆäº§ä¸šå†…å‚æ—¥æŠ¥..."
          
          # è¿è¡Œä¸»ç¨‹åºç”Ÿæˆæ—¥æŠ¥
          echo "ğŸš€ è¿è¡Œæ—¥æŠ¥ç”Ÿæˆ..."
          python main.py --mode=daily || python main.py
          
          # æ£€æŸ¥ç”Ÿæˆçš„æ—¥æŠ¥æ–‡ä»¶
          if [ -f "data/daily_report.md" ]; then
            echo "âœ… æ—¥æŠ¥ç”ŸæˆæˆåŠŸ"
            mkdir -p reports
            cp data/daily_report.md "reports/daily_report_${{ steps.date.outputs.target_date }}.md"
            
            # æ˜¾ç¤ºå‰å‡ è¡Œ
            echo "ğŸ“„ æ—¥æŠ¥é¢„è§ˆ:"
            head -20 "reports/daily_report_${{ steps.date.outputs.target_date }}.md"
          else
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æ—¥æŠ¥æ–‡ä»¶
            echo "ğŸ” æŸ¥æ‰¾æ—¥æŠ¥æ–‡ä»¶..."
            find . -name "*report*.md" -o -name "*æ—¥æŠ¥*.md" | head -5
            
            # åˆ›å»ºç®€å•çš„æ—¥æŠ¥
            echo "ğŸ“ åˆ›å»ºç®€å•æ—¥æŠ¥..."
            mkdir -p reports
            cat > "reports/daily_report_${{ steps.date.outputs.target_date }}.md" << EOF
# ğŸ“Š äº§ä¸šå†…å‚æ—¥æŠ¥ ${{ steps.date.outputs.target_date }}

## ğŸ“ˆ æ•°æ®ç»Ÿè®¡
- ç›‘æµ‹æ—¶é—´: ${{ steps.date.outputs.target_date }}
- æ•°æ®æ¥æº: GitHub Actions è‡ªåŠ¨é‡‡é›†
- æ–°é—»æ•°é‡: $(python -c "import json; f=open('data/daily_input.json'); data=json.load(f); print(data.get('count', 0)); f.close()")

## ğŸ” ç³»ç»ŸçŠ¶æ€
- æ•°æ®é‡‡é›†: ${{ needs.crawl-and-process.outputs.has_data }}
- ç”Ÿæˆæ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')

## ğŸ“Œ æç¤º
å½“å‰ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œè¯¦ç»†æ•°æ®æ­£åœ¨å¼€å‘ä¸­ã€‚

EOF
          fi
          
      - name: ğŸ“¤ å‘é€é£ä¹¦é€šçŸ¥
        if: success()
        env:
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        run: |
          echo "ğŸ“¨ å‘é€é£ä¹¦é€šçŸ¥..."
          
          report_file="reports/daily_report_${{ steps.date.outputs.target_date }}.md"
          if [ -f "$report_file" ]; then
            # è¯»å–æ—¥æŠ¥å†…å®¹
            report_content=$(cat "$report_file")
            
            # æ„é€ ç®€å•çš„é£ä¹¦æ¶ˆæ¯
            message=$(cat << EOF
{
  "msg_type": "text",
  "content": {
    "text": "ç±»å‹ï¼šwebhook content.daily_report\nğŸ“Š äº§ä¸šå†…å‚æ—¥æŠ¥ ${{ steps.date.outputs.target_date }}\n\n$(echo "$report_content" | head -30 | sed 's/"/\\"/g')\n\n...å®Œæ•´æŠ¥å‘Šè¯·æŸ¥çœ‹é™„ä»¶"
  }
}
EOF
            )
            
            # å‘é€é£ä¹¦æ¶ˆæ¯
            echo "ğŸ”„ å‘é€æ¶ˆæ¯..."
            curl -X POST -H "Content-Type: application/json" \
              -d "$message" \
              "$FEISHU_WEBHOOK_URL"
            
            echo "âœ… é£ä¹¦é€šçŸ¥å‘é€å®Œæˆ"
          else
            echo "âŒ æ—¥æŠ¥æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å‘é€"
          fi
          
      - name: ğŸ“ å½’æ¡£æŠ¥å‘Š
        run: |
          echo "ğŸ“ å½’æ¡£æŠ¥å‘Š..."
          mkdir -p reports/archive
          if [ -f "reports/daily_report_${{ steps.date.outputs.target_date }}.md" ]; then
            cp "reports/daily_report_${{ steps.date.outputs.target_date }}.md" reports/archive/
            echo "âœ… æŠ¥å‘Šå·²å½’æ¡£"
          fi
          
      - name: ğŸ—‘ï¸ æ¸…ç†æ—§æ•°æ®
        run: |
          echo "ğŸ§¹ æ¸…ç†æ—§æ•°æ®..."
          find data/hourly -name "*.json" -mtime +3 -delete
          find data/raw -name "*.txt" -mtime +3 -delete
          
      - name: ğŸ“ æäº¤æ—¥æŠ¥
        if: always()
        run: |
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          
          # æ·»åŠ æŠ¥å‘Šæ–‡ä»¶
          git add reports/
          git add data/daily_report.md data/daily_input.json 2>/dev/null || true
          
          if git diff --cached --quiet; then
            echo "ğŸ“­ æ— æ–°æŠ¥å‘Šéœ€è¦æäº¤"
          else
            echo "ğŸ“ æäº¤æ—¥æŠ¥..."
            git commit -m "ğŸ“‹ äº§ä¸šå†…å‚æ—¥æŠ¥: ${{ steps.date.outputs.target_date }}"
            
            # é‡è¯•æ¨é€
            for i in {1..3}; do
              echo "å°è¯•æ¨é€ ($i/3)..."
              if git pull --rebase origin main && git push origin main; then
                echo "âœ… æ¨é€æˆåŠŸ"
                break
              else
                echo "âš ï¸ æ¨é€å¤±è´¥ï¼Œç­‰å¾…10ç§’åé‡è¯•..."
                sleep 10
              fi
            done
          fi
